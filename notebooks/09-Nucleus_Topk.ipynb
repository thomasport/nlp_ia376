{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"09-Nucleus_Topk.ipynb","provenance":[{"file_id":"1Wj4ilb6WNq-6pCO83gD1MFZxU5vmTjBc","timestamp":1589227278251},{"file_id":"1-PhFRy_ecPdkt3ObW6DaTWICXdppNYpA","timestamp":1588599333980},{"file_id":"1nBqzYoRkn-XQp_ViI0VLBkW89p1VPT2B","timestamp":1587922156396},{"file_id":"1ONeS-lZ3vVqThueoTvQRMnZ_rJJB1yOl","timestamp":1587582119737}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"acec784780a44fff97cf4be95dd5475d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3055dc06ad7b4ecba2580477db60d9d5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5f65a3c2b3e247f3bf79c2cb33d4b05b","IPY_MODEL_e6b437360c9a44cc830a74138e334f9b"]}},"3055dc06ad7b4ecba2580477db60d9d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"5f65a3c2b3e247f3bf79c2cb33d4b05b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_15bbabe049b448d18021b872eb69bef8","_dom_classes":[],"description":"Testing: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0ca7db16cbee4351a0eaebfc4af2c616"}},"e6b437360c9a44cc830a74138e334f9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8e1ec5c47a214b9db1afd18c962e3447","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2500/2500 [16:05&lt;00:00,  2.59it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_080da77424184195b7b7843e4d67dcaa"}},"15bbabe049b448d18021b872eb69bef8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0ca7db16cbee4351a0eaebfc4af2c616":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e1ec5c47a214b9db1afd18c962e3447":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"080da77424184195b7b7843e4d67dcaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4bd1be7780845248e434e6ac9a376fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fe38abce76884f72bb7e8b3477e3046a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_50d5b82cac3d42bc881886ca9a87b2d6","IPY_MODEL_aecafd3ac73f45e3bbe5e697e00d64ab"]}},"fe38abce76884f72bb7e8b3477e3046a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"50d5b82cac3d42bc881886ca9a87b2d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ad07c571ae07472bbe548e3eaa830de0","_dom_classes":[],"description":"Testing: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_743609dad2e648f397be6d814cca195a"}},"aecafd3ac73f45e3bbe5e697e00d64ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cc37515d8af04fd7b6e37eda32871445","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2500/2500 [14:29&lt;00:00,  2.88it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c3df3ac9a3b84d36a9ca620a56d5fe4d"}},"ad07c571ae07472bbe548e3eaa830de0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"743609dad2e648f397be6d814cca195a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cc37515d8af04fd7b6e37eda32871445":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c3df3ac9a3b84d36a9ca620a56d5fe4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"93105db653db4215b442e964f3b14836":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2c72612152274873b5e9ec12ddef696b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_23aa8f3a16354343b896ee5c940bd9d2","IPY_MODEL_9c4a72d9e55f4a0591dec09af75909d9"]}},"2c72612152274873b5e9ec12ddef696b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"23aa8f3a16354343b896ee5c940bd9d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_190efba9359748ab98bedd42e2843658","_dom_classes":[],"description":"Testing: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f1efaaa5f7184b92827feeab31ffc028"}},"9c4a72d9e55f4a0591dec09af75909d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_76949c0e80774de6b7affd2d55d0c66b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2500/2500 [15:34&lt;00:00,  2.68it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f624d97d659a4cf7a92bef89931f74ba"}},"190efba9359748ab98bedd42e2843658":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f1efaaa5f7184b92827feeab31ffc028":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"76949c0e80774de6b7affd2d55d0c66b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f624d97d659a4cf7a92bef89931f74ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fa45cf8969e84dfa9ef38956a594b409":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_819c4074b47b46eda3e1e3ffc1ddec5c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6c2c979cf2084c89a1e102ceef689d3f","IPY_MODEL_ffbb74da8cbd41e5b28ba1da1e0e910c"]}},"819c4074b47b46eda3e1e3ffc1ddec5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"6c2c979cf2084c89a1e102ceef689d3f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a9d573ef720f42a18874637644ea3c3a","_dom_classes":[],"description":"Testing: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_62df1ce3b8004d00a0d645b67785ebec"}},"ffbb74da8cbd41e5b28ba1da1e0e910c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b8e7bdf9b6884fd78cc7b5b463c9d591","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2500/2500 [14:41&lt;00:00,  2.84it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a5fee794483e4eb18f40e4340984f5f2"}},"a9d573ef720f42a18874637644ea3c3a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"62df1ce3b8004d00a0d645b67785ebec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8e7bdf9b6884fd78cc7b5b463c9d591":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a5fee794483e4eb18f40e4340984f5f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74aab7ccb558407fbfdde78af78b5eb2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_018ee9aa1cf648a3b9dd0bc136f26277","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a587ab5355584be885d64841c02c158c","IPY_MODEL_8ed17bc05fa84b99baeef1d246ea22b1"]}},"018ee9aa1cf648a3b9dd0bc136f26277":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"a587ab5355584be885d64841c02c158c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8df7c6234abc4df697e5e77d01c387f2","_dom_classes":[],"description":"Testing: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e3f820413c324d36a82ffb698d8ca31e"}},"8ed17bc05fa84b99baeef1d246ea22b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7006d6c50e784a12be23a8dd8e322122","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2500/2500 [19:02&lt;00:00,  2.19it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3ed0355d2eda4104bd129dbf392df674"}},"8df7c6234abc4df697e5e77d01c387f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e3f820413c324d36a82ffb698d8ca31e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7006d6c50e784a12be23a8dd8e322122":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3ed0355d2eda4104bd129dbf392df674":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e5df94aa667e4784970cb49ab1fc3160":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1d4b4944795e4c5aae376b7e5f2930e8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4633d68144fb47bc8d3a0c39b7e6f371","IPY_MODEL_d8bcd745e82644309d6e7f3266feeba6"]}},"1d4b4944795e4c5aae376b7e5f2930e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"4633d68144fb47bc8d3a0c39b7e6f371":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_72ec3ed68cce4f7aa299e80e977df69c","_dom_classes":[],"description":"Testing: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3791aa1f74034e6684c0947fc7b20815"}},"d8bcd745e82644309d6e7f3266feeba6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b4160f072c0b4631ad08da0ddfe29387","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2500/2500 [17:00&lt;00:00,  2.45it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a033689549b14960b74ddf1534bb3daf"}},"72ec3ed68cce4f7aa299e80e977df69c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3791aa1f74034e6684c0947fc7b20815":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4160f072c0b4631ad08da0ddfe29387":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a033689549b14960b74ddf1534bb3daf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1OG5DT_dm6mk","colab_type":"text"},"source":["# Nucleus e Top K Decoding para tradução\n"]},{"cell_type":"markdown","metadata":{"id":"Od7iUgHy5SSi","colab_type":"text"},"source":["Neste colab iremos utilizar duas técnicas de decoding (top k e nucleus) para a tarefa de tradução.\n"]},{"cell_type":"code","metadata":{"id":"0mXaMmG4cb-F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"status":"ok","timestamp":1589419090694,"user_tz":180,"elapsed":10223,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"1e8acfdd-13e9-48a2-8fb4-3906d63d06d4"},"source":["! pip install transformers\n","! pip install --quiet pytorch-lightning==0.7.5\n","! pip install sacrebleu --quiet"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.90)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ob7qL6kUVjbu","colab_type":"code","colab":{}},"source":["# Importar todos os pacotes de uma só vez para evitar duplicados ao longo do notebook.\n","import gzip\n","import nvidia_smi\n","import os\n","import random\n","import torch\n","import torch.nn.functional as F\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","import sacrebleu\n","from google.colab import drive\n","\n","from transformers import T5ForConditionalGeneration\n","from transformers import T5Tokenizer\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","\n","from typing import Dict\n","from typing import List\n","from typing import Tuple"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aj6eazCpxOaT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1589419090696,"user_tz":180,"elapsed":10185,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"bd1b3679-caca-44ec-c6dd-e5e2f59a9160"},"source":["drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bJlZDb1VY29r","colab_type":"code","colab":{}},"source":["# Important: Fix seeds so we can replicate results\n","seed = 123\n","random.seed(seed) \n","# np.random.seed(seed)\n","torch.random.manual_seed(seed)\n","torch.cuda.manual_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fs5GhqmMTNNS","colab_type":"text"},"source":["DICA para modelos reais: Um modelo otimizado deve manter o uso de GPU próximo a 100% durante o treino.\n","Vamos utilizar a bilioteca abaixo para monitorar isso. Note que no modelo simples utilizado aqui o uso não vai chegar a 100%."]},{"cell_type":"code","metadata":{"id":"UGNTZKHrTM6l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1589419090699,"user_tz":180,"elapsed":10144,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"0096615a-be5d-46fa-db5e-c6cfb139da4b"},"source":["nvidia_smi.nvmlInit()\n","handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n","print(f\"Device name: {nvidia_smi.nvmlDeviceGetName(handle)}\")\n","\n","def gpu_usage():\n","    global handle\n","    return str(nvidia_smi.nvmlDeviceGetUtilizationRates(handle).gpu) + '%'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Device name: b'Tesla T4'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FgW-boJLU0wU","colab_type":"code","colab":{}},"source":["# Configurações gerais\n","model_name = \"t5-small\"\n","batch_size = 2\n","source_max_length = 11\n","target_max_length = 7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_J2LamxI1CQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589419093906,"user_tz":180,"elapsed":13315,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"9f753887-e5f2-4e0e-ab0d-e0704dd92f0f"},"source":["tokenizer = T5Tokenizer.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n","INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-small-config.json from cache at /root/.cache/torch/transformers/26561bc9e840d8945f475d0d4c4b9df32025eadd79894b867b570cb1d09e67a9.3817cc1260a6b941b17af62b4f2a942b9825f209d8e2eed99e79e96f85f59aab\n","INFO:transformers.configuration_utils:Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 8,\n","  \"num_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/t5-small-pytorch_model.bin from cache at /root/.cache/torch/transformers/9b662cba85524bef76fff5eb77d767407ac36f3fe492869331c011efd2b3a082.04cbd562eb01c8cec40cf5fefcc83823e6ba146bd2a758202a770beb7d80bb5d\n","INFO:transformers.modeling_utils:Weights of T5ForConditionalGeneration not initialized from pretrained model: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","INFO:transformers.modeling_utils:Weights from pretrained model not used in T5ForConditionalGeneration: ['encoder.block.0.layer.0.layer_norm.bias', 'encoder.block.0.layer.1.layer_norm.bias', 'encoder.block.1.layer.0.layer_norm.bias', 'encoder.block.1.layer.1.layer_norm.bias', 'encoder.block.2.layer.0.layer_norm.bias', 'encoder.block.2.layer.1.layer_norm.bias', 'encoder.block.3.layer.0.layer_norm.bias', 'encoder.block.3.layer.1.layer_norm.bias', 'encoder.block.4.layer.0.layer_norm.bias', 'encoder.block.4.layer.1.layer_norm.bias', 'encoder.block.5.layer.0.layer_norm.bias', 'encoder.block.5.layer.1.layer_norm.bias', 'encoder.final_layer_norm.bias', 'decoder.block.0.layer.0.layer_norm.bias', 'decoder.block.0.layer.1.layer_norm.bias', 'decoder.block.0.layer.2.layer_norm.bias', 'decoder.block.1.layer.0.layer_norm.bias', 'decoder.block.1.layer.1.layer_norm.bias', 'decoder.block.1.layer.2.layer_norm.bias', 'decoder.block.2.layer.0.layer_norm.bias', 'decoder.block.2.layer.1.layer_norm.bias', 'decoder.block.2.layer.2.layer_norm.bias', 'decoder.block.3.layer.0.layer_norm.bias', 'decoder.block.3.layer.1.layer_norm.bias', 'decoder.block.3.layer.2.layer_norm.bias', 'decoder.block.4.layer.0.layer_norm.bias', 'decoder.block.4.layer.1.layer_norm.bias', 'decoder.block.4.layer.2.layer_norm.bias', 'decoder.block.5.layer.0.layer_norm.bias', 'decoder.block.5.layer.1.layer_norm.bias', 'decoder.block.5.layer.2.layer_norm.bias', 'decoder.final_layer_norm.bias']\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OMen-JFKLFCb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1589419093908,"user_tz":180,"elapsed":13297,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"e80c2164-c88a-49fe-ffdc-af5436eb0c52"},"source":["# Importante: adicionar end-of-sequence token.\n","source = ['translate English to German: I like pizza </s>','translate English to German: I dont care </s>']\n","\n","source_encoded = tokenizer.batch_encode_plus(\n","    source, add_special_tokens=True,\n","    max_length=source_max_length,\n","    pad_to_max_length=True,\n","    return_token_type_ids=True,\n","    return_attention_mask=True,\n","    return_tensors='pt')\n","source_token_ids = source_encoded['input_ids']\n","source_mask = source_encoded['attention_mask']\n","source_token_ids"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[13959,  1566,    12,  2968,    10,    27,   114,  6871,     1,     0,\n","             0],\n","        [13959,  1566,    12,  2968,    10,    27,  2483,   124,     1,     0,\n","             0]])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"sfCPK9IbJjtT","colab_type":"text"},"source":["# Implementação greedy decoding do model.generate()"]},{"cell_type":"code","metadata":{"id":"BqjPb7J9JYCg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":629},"executionInfo":{"status":"ok","timestamp":1589419094300,"user_tz":180,"elapsed":13668,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"116a5b90-9926-46c7-bcf4-b48740c526f3"},"source":["decoded_ids = torch.full((source_token_ids.shape[0], 1),\n","                          model.config.decoder_start_token_id,\n","                          dtype=torch.long).to(source_token_ids.device)\n","\n","encoder_hidden_states = model.get_encoder()(source_token_ids,\n","                                            attention_mask=source_mask)\n","print('encoder_hidden_states[0].shape', encoder_hidden_states[0].shape)\n","print('decoded_ids.shape', decoded_ids.shape)\n","\n","for step in range(target_max_length):\n","    logits, _, _ = model(decoder_input_ids=decoded_ids,\n","                      encoder_outputs=encoder_hidden_states,\n","                      attention_mask=source_mask)\n","\n","    next_token_logits = logits[:, -1, :]\n","    next_token_id = next_token_logits.argmax(1).unsqueeze(-1)\n","    decoded_ids = torch.cat([decoded_ids, next_token_id], dim=-1)\n","    print('-' * 50)\n","    print('step', step)\n","    print('logits.shape', logits.shape)\n","    print('decoded_ids.shape', decoded_ids.shape)\n","\n","print('decoded tokens: ', tokenizer.convert_ids_to_tokens(decoded_ids[0]))\n","print('final: ', tokenizer.decode(decoded_ids[0]))\n","print('decoded tokens: ', tokenizer.convert_ids_to_tokens(decoded_ids[1]))\n","print('final: ', tokenizer.decode(decoded_ids[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["encoder_hidden_states[0].shape torch.Size([2, 11, 512])\n","decoded_ids.shape torch.Size([2, 1])\n","--------------------------------------------------\n","step 0\n","logits.shape torch.Size([2, 1, 32128])\n","decoded_ids.shape torch.Size([2, 2])\n","--------------------------------------------------\n","step 1\n","logits.shape torch.Size([2, 2, 32128])\n","decoded_ids.shape torch.Size([2, 3])\n","--------------------------------------------------\n","step 2\n","logits.shape torch.Size([2, 3, 32128])\n","decoded_ids.shape torch.Size([2, 4])\n","--------------------------------------------------\n","step 3\n","logits.shape torch.Size([2, 4, 32128])\n","decoded_ids.shape torch.Size([2, 5])\n","--------------------------------------------------\n","step 4\n","logits.shape torch.Size([2, 5, 32128])\n","decoded_ids.shape torch.Size([2, 6])\n","--------------------------------------------------\n","step 5\n","logits.shape torch.Size([2, 6, 32128])\n","decoded_ids.shape torch.Size([2, 7])\n","--------------------------------------------------\n","step 6\n","logits.shape torch.Size([2, 7, 32128])\n","decoded_ids.shape torch.Size([2, 8])\n","decoded tokens:  ['<pad>', '▁Ich', '▁mag', '▁Pizza', '</s>', '</s>', '</s>', '</s>']\n","final:  Ich mag Pizza\n","decoded tokens:  ['<pad>', '▁Ich', '▁', 'm', 'uß', '▁mich', '▁nicht', '▁']\n","final:  Ich muß mich nicht \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6BA4UTsaJYQd","colab_type":"text"},"source":["# Validando com a implementação do HuggingFace-transformers"]},{"cell_type":"code","metadata":{"id":"mzp4xnpdJIL5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1589419094306,"user_tz":180,"elapsed":13653,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"c7bf5c30-5892-4753-8579-dd8f90df6377"},"source":["outputs = model.generate(input_ids=source_token_ids,\n","                         attention_mask=source_mask,\n","                         max_length=target_max_length,\n","                         do_sample=False)\n","print('decoded tokens: ', tokenizer.convert_ids_to_tokens(outputs[0]))\n","print('final: ', tokenizer.decode(outputs[0]))\n","print('decoded tokens: ', tokenizer.convert_ids_to_tokens(outputs[1]))\n","print('final: ', tokenizer.decode(outputs[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["decoded tokens:  ['<pad>', '▁Ich', '▁mag', '▁Pizza', '</s>', '<pad>', '<pad>']\n","final:  Ich mag Pizza\n","decoded tokens:  ['<pad>', '▁Ich', '▁', 'm', 'uß', '▁mich', '▁nicht']\n","final:  Ich muß mich nicht\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B3oY4qnQzTQt","colab_type":"text"},"source":["# Criando funções de decodificação"]},{"cell_type":"code","metadata":{"id":"VrdIWOuMfWJk","colab_type":"code","colab":{}},"source":["def nucleus_sampling(logits,p = torch.tensor(0.95)):\n","\n","  #Definindo probabilidades e ordenando-as\n","  probs = F.softmax(logits)\n","  probs_sorted, indices = torch.sort(probs, descending=True)\n","  \n","  #Calculando a probabilidade acumulada e comparando com o threshold\n","  probs_cum_sum = torch.cumsum(probs_sorted,dim=-1)\n","  \n","  probs_greater_than_p = probs_cum_sum > p\n","  print(probs_greater_than_p)\n","  one_token_prob = probs_greater_than_p.all(-1)\n","  probs_greater_than_p[one_token_prob,0] = False \n","  #Atribuindo zero para tokens não candidatos, e normalizando probabilidade para candidatos\n","  probs_sorted[probs_greater_than_p] = 0\n","  probs_sorted  = probs_sorted/p \n","  \n","  #Amostrando de acordo com a probabilidade \n","  print(probs_sorted)\n","  token_index = torch.multinomial(probs_sorted,1)\n","  predicted_tokens = indices[0][token_index]\n","\n","  return predicted_tokens\n","\n","def topk_sampling(logits, k = 10):\n","\n","  logits, tokens = torch.topk(logits,k,dim=-1) # Selecionando os k maiores logitos.\n","  probs = F.softmax(logits) # Calculo da probabilidade\n","  token_index = torch.multinomial(probs,1) #Amostrando de acordo com a probabilidade\n","  print(tokens.shape)\n","  print(token_index.shape)\n","  predicted_tokens = torch.gather(tokens,-1,token_index)\n","  print(predicted_tokens.shape)\n","  return predicted_tokens  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"25KK6c90i4Mw","colab_type":"text"},"source":["# Teste de \"Top-K Sampling\""]},{"cell_type":"code","metadata":{"id":"R4CtM3sEds1q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589419094653,"user_tz":180,"elapsed":13959,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"7a70fdd3-59e3-48d3-adf9-4fa07d59c1ee"},"source":["decoded_ids = torch.full((source_token_ids.shape[0], 1),\n","                          model.config.decoder_start_token_id,\n","                          dtype=torch.long).to(source_token_ids.device)\n","\n","encoder_hidden_states = model.get_encoder()(source_token_ids,\n","                                            attention_mask=source_mask)\n","print('encoder_hidden_states[0].shape', encoder_hidden_states[0].shape)\n","print('decoded_ids.shape', decoded_ids.shape)\n","\n","for step in range(target_max_length):\n","    logits, _, _ = model(decoder_input_ids=decoded_ids,\n","                      encoder_outputs=encoder_hidden_states,\n","                      attention_mask=source_mask)\n","    next_token_logits = logits[:, -1, :]\n","    \n","    next_token_id = topk_sampling(next_token_logits)\n","    # print(next_token_id.shape)\n","    decoded_ids = torch.cat([decoded_ids, next_token_id], dim=-1)\n","\n","    print('-' * 50)\n","    print('step', step)\n","    print('logits.shape', logits.shape)\n","    print('decoded_ids.shape', decoded_ids.shape)\n","\n","print('decoded tokens: ', tokenizer.convert_ids_to_tokens(decoded_ids[0]))\n","print('final: ', tokenizer.decode(decoded_ids[0]))\n","print('decoded tokens: ', tokenizer.convert_ids_to_tokens(decoded_ids[1]))\n","print('final: ', tokenizer.decode(decoded_ids[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["encoder_hidden_states[0].shape torch.Size([2, 11, 512])\n","decoded_ids.shape torch.Size([2, 1])\n","torch.Size([2, 10])\n","torch.Size([2, 1])\n","torch.Size([2, 1])\n","--------------------------------------------------\n","step 0\n","logits.shape torch.Size([2, 1, 32128])\n","decoded_ids.shape torch.Size([2, 2])\n","torch.Size([2, 10])\n","torch.Size([2, 1])\n","torch.Size([2, 1])\n","--------------------------------------------------\n","step 1\n","logits.shape torch.Size([2, 2, 32128])\n","decoded_ids.shape torch.Size([2, 3])\n","torch.Size([2, 10])\n","torch.Size([2, 1])\n","torch.Size([2, 1])\n","--------------------------------------------------\n","step 2\n","logits.shape torch.Size([2, 3, 32128])\n","decoded_ids.shape torch.Size([2, 4])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([2, 10])\n","torch.Size([2, 1])\n","torch.Size([2, 1])\n","--------------------------------------------------\n","step 3\n","logits.shape torch.Size([2, 4, 32128])\n","decoded_ids.shape torch.Size([2, 5])\n","torch.Size([2, 10])\n","torch.Size([2, 1])\n","torch.Size([2, 1])\n","--------------------------------------------------\n","step 4\n","logits.shape torch.Size([2, 5, 32128])\n","decoded_ids.shape torch.Size([2, 6])\n","torch.Size([2, 10])\n","torch.Size([2, 1])\n","torch.Size([2, 1])\n","--------------------------------------------------\n","step 5\n","logits.shape torch.Size([2, 6, 32128])\n","decoded_ids.shape torch.Size([2, 7])\n","torch.Size([2, 10])\n","torch.Size([2, 1])\n","torch.Size([2, 1])\n","--------------------------------------------------\n","step 6\n","logits.shape torch.Size([2, 7, 32128])\n","decoded_ids.shape torch.Size([2, 8])\n","decoded tokens:  ['<pad>', '▁Ich', '▁mag', '▁Pizza', '</s>', '</s>', '.', '</s>']\n","final:  Ich mag Pizza.\n","decoded tokens:  ['<pad>', '▁Ich', '▁', 'm', 'uß', '▁mich', '▁nicht', '▁um']\n","final:  Ich muß mich nicht um\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oEhZkstyPgaI","colab_type":"text"},"source":["# Validando com a implementação do HuggingFace-transformers"]},{"cell_type":"code","metadata":{"id":"9Sx7edJePac1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1589419095001,"user_tz":180,"elapsed":14281,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"8a48a1bc-fb2a-416f-f9ef-cca823b52adb"},"source":["outputs = model.generate(input_ids=source_token_ids,\n","                         attention_mask=source_mask,\n","                         max_length=target_max_length,\n","                         do_sample=True,\n","                         top_k = 10)\n","print('decoded tokens: ', tokenizer.convert_ids_to_tokens(outputs[0]))\n","print('final: ', tokenizer.decode(outputs[0]))\n","print('decoded tokens: ', tokenizer.convert_ids_to_tokens(outputs[1]))\n","print('final: ', tokenizer.decode(outputs[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["decoded tokens:  ['<pad>', '▁Ich', '▁mag', '▁Pizza', '</s>', '<pad>', '<pad>']\n","final:  Ich mag Pizza\n","decoded tokens:  ['<pad>', '▁Ich', '▁', 't', 'u', 'e', '▁mich']\n","final:  Ich tue mich\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U-AK6HqjirG0","colab_type":"text"},"source":["# Teste de \"Nucleus Sampling\" \n"]},{"cell_type":"code","metadata":{"id":"npz1zxZ6wKFT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589419114914,"user_tz":180,"elapsed":1366,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"80102ce9-a9e3-40a0-a6cb-b03526d68349"},"source":["decoded_ids = torch.full((source_token_ids.shape[0], 1),\n","                          model.config.decoder_start_token_id,\n","                          dtype=torch.long).to(source_token_ids.device)\n","\n","encoder_hidden_states = model.get_encoder()(source_token_ids,\n","                                            attention_mask=source_mask)\n","print('encoder_hidden_states[0].shape', encoder_hidden_states[0].shape)\n","print('decoded_ids.shape', decoded_ids.shape)\n","\n","for step in range(target_max_length):\n","    logits, _, _ = model(decoder_input_ids=decoded_ids,\n","                      encoder_outputs=encoder_hidden_states,\n","                      attention_mask=source_mask)\n","    next_token_logits = logits[:, -1, :]\n","    next_token_id = nucleus_sampling(next_token_logits)\n","    decoded_ids = torch.cat([decoded_ids, next_token_id], dim=-1)\n","\n","    print('-' * 50)\n","    print('step', step)\n","    print('logits.shape', logits.shape)\n","    print('decoded_ids.shape', decoded_ids.shape)\n","\n","print('decoded tokens: ', tokenizer.convert_ids_to_tokens(decoded_ids[0]))\n","print('final: ', tokenizer.decode(decoded_ids[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["encoder_hidden_states[0].shape torch.Size([2, 11, 512])\n","decoded_ids.shape torch.Size([2, 1])\n","tensor([[False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True]])\n","tensor([[0.4553, 0.0759, 0.0307,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.3804, 0.2212, 0.0561,  ..., 0.0000, 0.0000, 0.0000]],\n","       grad_fn=<DivBackward0>)\n","--------------------------------------------------\n","step 0\n","logits.shape torch.Size([2, 1, 32128])\n","decoded_ids.shape torch.Size([2, 2])\n","tensor([[False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True]])\n","tensor([[0.9113, 0.0408, 0.0277,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.3041, 0.2391, 0.0777,  ..., 0.0000, 0.0000, 0.0000]],\n","       grad_fn=<DivBackward0>)\n","--------------------------------------------------\n","step 1\n","logits.shape torch.Size([2, 2, 32128])\n","decoded_ids.shape torch.Size([2, 3])\n","tensor([[False,  True,  True,  ...,  True,  True,  True],\n","        [ True,  True,  True,  ...,  True,  True,  True]])\n","tensor([[0.9796, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [1.0369, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n","       grad_fn=<DivBackward0>)\n","--------------------------------------------------\n","step 2\n","logits.shape torch.Size([2, 3, 32128])\n","decoded_ids.shape torch.Size([2, 4])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  after removing the cwd from sys.path.\n"],"name":"stderr"},{"output_type":"stream","text":["tensor([[False,  True,  True,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True]])\n","tensor([[0.9587, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.1072, 0.1020, 0.0383,  ..., 0.0000, 0.0000, 0.0000]],\n","       grad_fn=<DivBackward0>)\n","--------------------------------------------------\n","step 3\n","logits.shape torch.Size([2, 4, 32128])\n","decoded_ids.shape torch.Size([2, 5])\n","tensor([[False,  True,  True,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True]])\n","tensor([[0.9858, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.7113, 0.0426, 0.0153,  ..., 0.0000, 0.0000, 0.0000]],\n","       grad_fn=<DivBackward0>)\n","--------------------------------------------------\n","step 4\n","logits.shape torch.Size([2, 5, 32128])\n","decoded_ids.shape torch.Size([2, 6])\n","tensor([[False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True]])\n","tensor([[0.5548, 0.0448, 0.0425,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.9130, 0.0145, 0.0074,  ..., 0.0000, 0.0000, 0.0000]],\n","       grad_fn=<DivBackward0>)\n","--------------------------------------------------\n","step 5\n","logits.shape torch.Size([2, 6, 32128])\n","decoded_ids.shape torch.Size([2, 7])\n","tensor([[False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True]])\n","tensor([[0.1371, 0.0450, 0.0190,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.1810, 0.1042, 0.0535,  ..., 0.0000, 0.0000, 0.0000]],\n","       grad_fn=<DivBackward0>)\n","--------------------------------------------------\n","step 6\n","logits.shape torch.Size([2, 7, 32128])\n","decoded_ids.shape torch.Size([2, 8])\n","decoded tokens:  ['<pad>', '▁Ich', '▁mag', '▁Pizza', '</s>', '</s>', ',', '</s>']\n","final:  Ich mag Pizza,\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"49A-NN3ajGd3","colab_type":"text"},"source":["# Integrando sampling para o modelo treinado"]},{"cell_type":"code","metadata":{"id":"ziDhL3nQyBtH","colab_type":"code","colab":{}},"source":["# Configurações gerais\n","model_name = \"t5-small\"\n","batch_size = 8\n","accumulate_grad_batches = 8\n","source_max_length = 128\n","target_max_length = 128\n","learning_rate = 5e-3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fyD7NLlWfyvh","colab_type":"code","colab":{}},"source":["class T5Finetuner(pl.LightningModule):\n","\n","    def __init__(self, tokenizer, train_dataloader, val_dataloader,\n","                 test_dataloader, learning_rate, target_max_length=32, \n","                 custom_decoding=False, mode_decoding='greedy'):\n","        super(T5Finetuner, self).__init__()\n","        \n","        self._train_dataloader = train_dataloader\n","        self._val_dataloader = val_dataloader\n","        self._test_dataloader = test_dataloader\n","\n","        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n","        \n","        self.tokenizer = tokenizer\n","        self.learning_rate = learning_rate\n","        self.target_max_length = target_max_length\n","\n","        self.custom_decoding = custom_decoding\n","        if mode_decoding in ['greedy','topk','nucleus']:\n","          self.mode_decoding = mode_decoding\n","        else:\n","          print(\"Decoding mode not recognized. Using greedy decoding\")\n","          seelf.mode_decoding = 'greedy'\n","\n","    def nucleus_sampling(self,logits,p = torch.tensor(0.95)):\n","\n","      #Definindo probabilidades e ordenando-as\n","      probs = F.softmax(logits)\n","      probs_sorted, indices = torch.sort(probs, descending=True)\n","      \n","      #Calculando a probabilidade acumulada e comparando com o threshold\n","      probs_cum_sum = torch.cumsum(probs_sorted,dim=-1)\n","      probs_greater_than_p = probs_cum_sum > p\n","      \n","      #Tratando o caso em que o primeiro token já tem mais que o limiar.\n","      one_token_prob = probs_greater_than_p.all(-1)\n","      probs_greater_than_p[one_token_prob,0] = False \n","\n","      #Atribuindo zero para tokens não candidatos, e normalizando probabilidade para candidatos\n","      probs_sorted[probs_greater_than_p] = 0\n","      probs_sorted  = probs_sorted/p \n","      \n","      #Amostrando de acordo com a probabilidade \n","      token_index = torch.multinomial(probs_sorted,1)\n","      predicted_tokens = torch.gather(indices,-1,token_index)\n","\n","      return predicted_tokens\n","\n","    def topk_sampling(self,logits, k = 10):\n","\n","      logits, tokens = torch.topk(logits,k,dim=-1) # Selecionando os k maiores logitos.\n","      probs = F.softmax(logits) # Calculo da probabilidade\n","      token_index = torch.multinomial(probs,1) #Amostrando de acordo com a probabilidade\n","      predicted_tokens = torch.gather(tokens,-1,token_index)\n","      return predicted_tokens  \n","\n","    def custom_decode(self,source_token_id, source_mask):\n","      decoded_ids = torch.full((source_token_id.shape[0], 1),\n","                          self.model.config.decoder_start_token_id,\n","                          dtype=torch.long).to(source_token_id.device)\n","      \n","      encoder_hidden_states = self.model.get_encoder()(source_token_id,\n","                                            attention_mask=source_mask)\n","      for step in range(self.target_max_length):\n","        logits, _, _ = self.model(decoder_input_ids=decoded_ids,\n","                          encoder_outputs=encoder_hidden_states,\n","                          attention_mask=source_mask)\n","        next_token_logits = logits[:, -1, :]\n","\n","        if self.mode_decoding=='topk':\n","          next_token_id = self.topk_sampling(next_token_logits)\n","        elif self.mode_decoding == 'nucleus':\n","          next_token_id = self.nucleus_sampling(next_token_logits)\n","        elif self.mode_decoding == 'greedy':\n","          next_token_id = next_token_logits.argmax(-1).unsqueeze(-1)\n","        # print(next_token_id.shape)\n","        # print(decoded_ids.shape)\n","        decoded_ids = torch.cat([decoded_ids, next_token_id], dim=-1)\n","\n","        # if next_token_id == self.model.config.eos_token_id:\n","        #   return decoder_ids\n","      \n","      return  decoded_ids\n","\n","    def forward(self, source_token_ids, source_mask, target_token_ids=None,\n","                target_mask=None):\n","       \n","        if self.training:\n","          loss, _, _, _ = self.model(input_ids=source_token_ids, attention_mask= source_mask, lm_labels=target_token_ids)\n","          return loss\n","        else:\n","          if self.custom_decoding:\n","            predicted_token_ids =  self.custom_decode(source_token_ids, source_mask)\n","          else:\n","            if self.mode_decoding == 'greedy':\n","              predicted_token_ids = self.model.generate(input_ids=source_token_ids, \n","                                                        max_length=self.target_max_length)\n","            elif self.mode_decoding == 'topk':\n","              predicted_token_ids = self.model.generate(input_ids=source_token_ids, \n","                                                        max_length=self.target_max_length,\n","                                                        do_sample = True,\n","                                                        top_k = 10)\n","\n","            elif self.mode_decoding == 'nucleus':\n","              predicted_token_ids = self.model.generate(input_ids=source_token_ids, \n","                                          max_length=self.target_max_length,\n","                                          do_sample = True,\n","                                          top_p = 0.95,\n","                                          top_k = 0)\n","\n","          return predicted_token_ids\n","\n","    def training_step(self, batch, batch_nb):\n","        # batch\n","        source_token_ids, source_mask, target_token_ids, target_mask, _, _ = batch\n","         \n","        # fwd\n","        loss = self(source_token_ids, source_mask, target_token_ids, target_mask)\n","\n","        # logs\n","        tensorboard_logs = {'train_loss': loss}\n","        progress_bar = {'gpu_usage': gpu_usage()}\n","        return {'loss': loss, 'log': tensorboard_logs,\n","                'progress_bar': progress_bar}\n","    \n","    def validation_step(self, batch, batch_nb):\n","        source_token_ids, source_mask, target_token_ids, target_mask, source, target = batch\n","        target = list(target)\n","        \n","        #Calculo BLEU\n","        tokens_predicted = self(source_token_ids, source_mask, target_token_ids, target_mask)\n","        sentences_predicted = [self.tokenizer.decode(x) for x in tokens_predicted.tolist()]\n","        bleu_i = sacrebleu.corpus_bleu(sentences_predicted, [target])\n","        \n","        avg_bleu = bleu_i.score\n","        \n","        # Dicionario para visualizar posteriormente\n","        sentences = {}\n","        sentences['Target'] = target[0]\n","        sentences['Source'] = source[0]\n","        sentences['Predicted'] = sentences_predicted[0]\n","\n","        progress_bar = {'gpu_usage': gpu_usage()}\n","        \n","        return {'val_bleu': avg_bleu, 'progress_bar': progress_bar, 'sentences': sentences}\n","\n","    def test_step(self, batch, batch_nb):\n","        source_token_ids, source_mask, target_token_ids, target_mask, source, target = batch\n","\n","        #Calculo BLEU\n","        tokens_predicted = self(source_token_ids, source_mask, target_token_ids, target_mask)\n","        sentences_predicted = [self.tokenizer.decode(x) for x in tokens_predicted.tolist()]\n","        bleu_i = sacrebleu.corpus_bleu(sentences_predicted, [target])\n","        avg_bleu = bleu_i.score\n","\n","        # Dicionario para visualizar posteriormente\n","        sentences = {}\n","        sentences['Target'] = target[0]\n","        sentences['Source'] = source[0]\n","        sentences['Predicted'] = sentences_predicted[0]\n","\n","        progress_bar = {'gpu_usage': gpu_usage()}\n","\n","        return {'test_bleu': avg_bleu, 'progress_bar': progress_bar, 'sentences': sentences}\n","\n","    def validation_epoch_end(self, outputs):\n","        avg_bleu = sum([x['val_bleu'] for x in outputs]) / len(outputs)\n","        sentences_dict = [x['sentences'] for x in outputs]\n","        \n","        for i in range(3):\n","          print('\\n\\n')\n","          print(\"Source:{}\".format(sentences_dict[i]['Source']))\n","          print(\"Target: {}\".format(sentences_dict[i]['Target']))\n","          print(\"Predicted: {}\".format(sentences_dict[i]['Predicted']))\n","          print('\\n\\n')\n","          break\n","        tensorboard_logs = {'avg_val_bleu': avg_bleu}\n","        \n","        return {'avg_val_bleu': avg_bleu, 'progress_bar': tensorboard_logs, 'log' : tensorboard_logs}\n","\n","    def test_epoch_end(self, outputs):\n","        avg_bleu = sum([x['test_bleu'] for x in outputs]) / len(outputs)\n","        sentences_dict = [x['sentences'] for x in outputs]\n","\n","        tensorboard_logs = {'avg_test_bleu': avg_bleu}\n","        for i in range(3):\n","          print('\\n\\n')\n","          print(\"Source:{}\".format(sentences_dict[i]['Source']))\n","          print(\"Target: {}\".format(sentences_dict[i]['Target']))\n","          print(\"Predicted: {}\".format(sentences_dict[i]['Predicted']))\n","          print('\\n\\n')\n","          break\n","        return {'avg_test_bleu': avg_bleu, 'progress_bar': tensorboard_logs}\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.Adam(\n","            [p for p in self.parameters() if p.requires_grad],\n","            lr=self.learning_rate, eps=1e-08)\n","\n","    def train_dataloader(self):\n","        return self._train_dataloader\n","\n","    def val_dataloader(self):\n","        return self._val_dataloader\n","\n","    def test_dataloader(self):\n","        return self._test_dataloader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pt4F0uY5v1nE","colab_type":"text"},"source":["# Carregando dados"]},{"cell_type":"code","metadata":{"id":"n4yiCvEzuI4l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1589419128753,"user_tz":180,"elapsed":6812,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"775cd580-bbbe-470b-8f1b-4f9e8064d9c8"},"source":["! wget -nc https://storage.googleapis.com/neuralresearcher_data/unicamp/ia376e_2020s1/paracrawl_enpt_train.tsv.gz\n","! wget -nc https://storage.googleapis.com/neuralresearcher_data/unicamp/ia376e_2020s1/paracrawl_enpt_test.tsv.gz"],"execution_count":null,"outputs":[{"output_type":"stream","text":["File ‘paracrawl_enpt_train.tsv.gz’ already there; not retrieving.\n","\n","File ‘paracrawl_enpt_test.tsv.gz’ already there; not retrieving.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rLy7rZE9woDf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":523},"executionInfo":{"status":"ok","timestamp":1589419135810,"user_tz":180,"elapsed":13445,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"e54aaa05-8bd9-4fb2-f6e4-09f8322f329b"},"source":["def load_text_pairs(path):\n","    text_pairs = []\n","    for line in gzip.open(path, mode='rt'):\n","        text_pairs.append(line.strip().split('\\t'))\n","    return text_pairs\n","\n","x_train = load_text_pairs('paracrawl_enpt_train.tsv.gz')\n","x_test = load_text_pairs('paracrawl_enpt_test.tsv.gz')\n","\n","# Embaralhamos o treino para depois fazermos a divisão treino/val.\n","random.shuffle(x_train)\n","\n","# Truncamos o dataset para 100k pares de treino e 5k pares de validação.\n","x_val = x_train[100000:105000]\n","x_train = x_train[:100000]\n","\n","for set_name, x in [('treino', x_train), ('validação', x_val), ('test', x_test)]:\n","    print(f'\\n{len(x)} amostras de {set_name}')\n","    print(f'3 primeiras amostras {set_name}:')\n","    for i, (source, target) in enumerate(x[:3]):\n","        print(f'{i}: source: {source}\\n   target: {target}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","100000 amostras de treino\n","3 primeiras amostras treino:\n","0: source: More Croatian words and phrases\n","   target: Mais palavras e frases em croata\n","1: source: Jerseys and pullovers, containing at least 50Â % by weight of wool and weighing 600Â g or more per article 6110 11 10 (PCE)\n","   target: Camisolas e pulôveres, com pelo menos 50 %, em peso, de lã e pesando 600g ou mais por unidade 6110 11 10 (PCE)\n","2: source: Atex Colombia SAS makes available its lead product, 100% natural liquid latex, excellent quality and price. ... Welding manizales caldas Colombia a DuckDuckGo\n","   target: Atex Colômbia SAS torna principal produto está disponível, látex líquido 100% natural, excelente qualidade e preço. ...\n","\n","5000 amostras de validação\n","3 primeiras amostras validação:\n","0: source: «You have hidden these things from the wise and the learned you have revealed them to the childlike»\n","   target: «Escondeste estas coisas aos sábios e entendidos e as revelaste aos pequenos»\n","1: source: Repair of computers, application programming, network installations, web design, graphic design, and also the most. Computer consulting in Santa Lucía\n","   target: Reparação de computadores, programação de aplicações, instalações de rede, web design, design gráfico, e também a.\n","2: source: He was born in Fafe (Braga) and he graduated in Law in Coimbra University.\n","   target: É natural de Fafe (Braga) e Licenciado em Direito pela Universidade de Coimbra.\n","\n","20000 amostras de test\n","3 primeiras amostras test:\n","0: source: In this way, the civil life of a nation matures, making it possible for all citizens to enjoy the fruits of genuine tolerance and mutual respect.\n","   target: Deste modo, a vida civil de uma nação amadurece, fazendo com que todos os cidadãos gozem dos frutos da tolerância genuína e do respeito mútuo.\n","1: source: 1999 XIII. Winnipeg, Canada July 23 to August 8\n","   target: 1999 XIII. Winnipeg, Canadá 23 de julho a 8 de agosto\n","2: source: In the mystery of Christmas, Christ's light shines on the earth, spreading, as it were, in concentric circles.\n","   target: No mistério do Natal, a luz de Cristo irradia-se sobre a terra, difundindo-se como círculos concêntricos.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vRybcwtows8h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1589419136176,"user_tz":180,"elapsed":13433,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"2f7c6a52-7abe-409a-80af-c0722e0fdcb3"},"source":["tokenizer = T5Tokenizer.from_pretrained(model_name)\n","\n","\n","class MyDataset(Dataset):\n","    def __init__(self, text_pairs: List[Tuple[str]], tokenizer,\n","                 source_max_length: int = 32, target_max_length: int = 32):\n","        self.tokenizer = tokenizer\n","        self.text_pairs = text_pairs\n","        self.source_max_length = source_max_length\n","        self.target_max_length = target_max_length\n","        self.tokenizer_eos = self.tokenizer.eos_token\n","        \n","    def __len__(self):\n","        return len(self.text_pairs)\n","    \n","    def __getitem__(self, idx):\n","        source, target = self.text_pairs[idx]\n","\n","        original_source = source\n","        original_target = target\n","\n","        source = 'translate English to Portuguese: ' + source + ' ' + self.tokenizer_eos\n","\n","        source_dict = tokenizer.encode_plus(source, max_length = self.source_max_length, pad_to_max_length = True)\n","        target_dict = tokenizer.encode_plus(target, max_length = self.target_max_length, pad_to_max_length = True)\n","\n","        source_token_ids = torch.tensor(source_dict['input_ids'])\n","        source_mask = torch.tensor(source_dict['attention_mask'])\n","        target_token_ids = torch.tensor(target_dict['input_ids'])\n","        target_mask = torch.tensor(target_dict['attention_mask'])\n","\n","        return (source_token_ids, source_mask, target_token_ids, target_mask,\n","                original_source, original_target)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"VZ64NAixwyIt","colab_type":"code","colab":{}},"source":["dataset_train = MyDataset(text_pairs=x_train,\n","                          tokenizer=tokenizer,\n","                          source_max_length=source_max_length,\n","                          target_max_length=target_max_length)\n","\n","dataset_val = MyDataset(text_pairs=x_val,\n","                        tokenizer=tokenizer,\n","                        source_max_length=source_max_length,\n","                        target_max_length=target_max_length)\n","\n","dataset_test = MyDataset(text_pairs=x_test,\n","                         tokenizer=tokenizer,\n","                         source_max_length=source_max_length,\n","                         target_max_length=target_max_length)\n","\n","train_dataloader = DataLoader(dataset_train, batch_size=batch_size,\n","                              shuffle=True, num_workers=4)\n","\n","val_dataloader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False, \n","                            num_workers=4)\n","\n","test_dataloader = DataLoader(dataset_test, batch_size=batch_size,\n","                             shuffle=False, num_workers=4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3tDooJXPx004","colab_type":"text"},"source":["# Overfit em 1 Batch"]},{"cell_type":"code","metadata":{"id":"-KvA6rd6xwKF","colab_type":"code","colab":{}},"source":["trainer = pl.Trainer(gpus = 1, \n","                    max_epochs=10,\n","                    check_val_every_n_epoch=1,\n","                    checkpoint_callback=False,  # Disable checkpoint saving\n","                    overfit_pct=0.005, \n","                     weights_summary=None)\n","\n","# Dataset usando apenas um batch de amostras de treino.\n","dataset_debug = MyDataset(text_pairs=x_train,\n","                          tokenizer=tokenizer,\n","                          source_max_length=source_max_length,\n","                          target_max_length=target_max_length)\n","\n","debug_dataloader = DataLoader(dataset_debug, batch_size=batch_size,\n","                              shuffle=False, num_workers=4)\n","\n","model = T5Finetuner(tokenizer=tokenizer,\n","                    train_dataloader=debug_dataloader,\n","                    val_dataloader=debug_dataloader,\n","                    test_dataloader=None,\n","                    learning_rate=learning_rate,\n","                    custom_decoding=True, \n","                    mode_decoding= 'nucleus')\n","\n","trainer.fit(model)\n","del model  # Para não ter estouro de mémoria da GPU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QQBtp8_zw8Wh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589419244452,"user_tz":180,"elapsed":3396,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"20dc556c-7dac-4ba4-8d9f-d40f0eba1bdd"},"source":["max_epochs = 4\n","\n","checkpoint_path = '/content/drive/My Drive/aula9_checkpoints/epoch=3.ckpt'\n","checkpoint_dir = os.path.dirname(os.path.abspath(checkpoint_path))\n","print(f'Files in {checkpoint_dir}: {os.listdir(checkpoint_dir)}')\n","print(f'Saving checkpoints to {checkpoint_dir}')\n","checkpoint_callback = ModelCheckpoint(filepath=checkpoint_dir,\n","                                      save_top_k=-1)  # Keeps all checkpoints.\n","\n","resume_from_checkpoint = None\n","if os.path.exists(checkpoint_path):\n","    print(f'Restoring checkpoint: {checkpoint_path}')\n","    resume_from_checkpoint = checkpoint_path\n","\n","trainer = pl.Trainer(gpus=1,\n","                    max_epochs=max_epochs,\n","                    check_val_every_n_epoch=1,\n","                    profiler=True,\n","                    accumulate_grad_batches=accumulate_grad_batches,\n","                    checkpoint_callback=checkpoint_callback,\n","                    progress_bar_refresh_rate=10,\n","                    resume_from_checkpoint=resume_from_checkpoint,\n","                      weights_summary=None)\n","\n","model = T5Finetuner(tokenizer=tokenizer,\n","                    train_dataloader=train_dataloader,\n","                    val_dataloader=val_dataloader,\n","                    test_dataloader=test_dataloader,\n","                    learning_rate=learning_rate,\n","                    custom_decoding = False,\n","                    mode_decoding  = 'greedy'\n","                    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:lightning:GPU available: True, used: True\n","INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"],"name":"stderr"},{"output_type":"stream","text":["Files in /content/drive/My Drive/aula9_checkpoints: ['epoch=0.ckpt', 'epoch=0_v0.ckpt', 'epoch=1.ckpt', 'epoch=0_v1.ckpt', 'epoch=1_v0.ckpt', 'epoch=0_v2.ckpt', 'epoch=1_v1.ckpt', 'epoch=0_v3.ckpt', 'epoch=1_v2.ckpt', 'epoch=2.ckpt', 'epoch=3.ckpt']\n","Saving checkpoints to /content/drive/My Drive/aula9_checkpoints\n","Restoring checkpoint: /content/drive/My Drive/aula9_checkpoints/epoch=3.ckpt\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-small-config.json from cache at /root/.cache/torch/transformers/26561bc9e840d8945f475d0d4c4b9df32025eadd79894b867b570cb1d09e67a9.3817cc1260a6b941b17af62b4f2a942b9825f209d8e2eed99e79e96f85f59aab\n","INFO:transformers.configuration_utils:Model config T5Config {\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 2048,\n","  \"d_kv\": 64,\n","  \"d_model\": 512,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_heads\": 8,\n","  \"num_layers\": 6,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"vocab_size\": 32128\n","}\n","\n","INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/t5-small-pytorch_model.bin from cache at /root/.cache/torch/transformers/9b662cba85524bef76fff5eb77d767407ac36f3fe492869331c011efd2b3a082.04cbd562eb01c8cec40cf5fefcc83823e6ba146bd2a758202a770beb7d80bb5d\n","INFO:transformers.modeling_utils:Weights of T5ForConditionalGeneration not initialized from pretrained model: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","INFO:transformers.modeling_utils:Weights from pretrained model not used in T5ForConditionalGeneration: ['encoder.block.0.layer.0.layer_norm.bias', 'encoder.block.0.layer.1.layer_norm.bias', 'encoder.block.1.layer.0.layer_norm.bias', 'encoder.block.1.layer.1.layer_norm.bias', 'encoder.block.2.layer.0.layer_norm.bias', 'encoder.block.2.layer.1.layer_norm.bias', 'encoder.block.3.layer.0.layer_norm.bias', 'encoder.block.3.layer.1.layer_norm.bias', 'encoder.block.4.layer.0.layer_norm.bias', 'encoder.block.4.layer.1.layer_norm.bias', 'encoder.block.5.layer.0.layer_norm.bias', 'encoder.block.5.layer.1.layer_norm.bias', 'encoder.final_layer_norm.bias', 'decoder.block.0.layer.0.layer_norm.bias', 'decoder.block.0.layer.1.layer_norm.bias', 'decoder.block.0.layer.2.layer_norm.bias', 'decoder.block.1.layer.0.layer_norm.bias', 'decoder.block.1.layer.1.layer_norm.bias', 'decoder.block.1.layer.2.layer_norm.bias', 'decoder.block.2.layer.0.layer_norm.bias', 'decoder.block.2.layer.1.layer_norm.bias', 'decoder.block.2.layer.2.layer_norm.bias', 'decoder.block.3.layer.0.layer_norm.bias', 'decoder.block.3.layer.1.layer_norm.bias', 'decoder.block.3.layer.2.layer_norm.bias', 'decoder.block.4.layer.0.layer_norm.bias', 'decoder.block.4.layer.1.layer_norm.bias', 'decoder.block.4.layer.2.layer_norm.bias', 'decoder.block.5.layer.0.layer_norm.bias', 'decoder.block.5.layer.1.layer_norm.bias', 'decoder.block.5.layer.2.layer_norm.bias', 'decoder.final_layer_norm.bias']\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"eZGqoNRDap8m","colab_type":"code","colab":{}},"source":["modes = ['greedy','topk','nucleus']\n","custom_decoding = [True, False]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZ1NOdOrbS6d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["acec784780a44fff97cf4be95dd5475d","3055dc06ad7b4ecba2580477db60d9d5","5f65a3c2b3e247f3bf79c2cb33d4b05b","e6b437360c9a44cc830a74138e334f9b","15bbabe049b448d18021b872eb69bef8","0ca7db16cbee4351a0eaebfc4af2c616","8e1ec5c47a214b9db1afd18c962e3447","080da77424184195b7b7843e4d67dcaa","a4bd1be7780845248e434e6ac9a376fe","fe38abce76884f72bb7e8b3477e3046a","50d5b82cac3d42bc881886ca9a87b2d6","aecafd3ac73f45e3bbe5e697e00d64ab","ad07c571ae07472bbe548e3eaa830de0","743609dad2e648f397be6d814cca195a","cc37515d8af04fd7b6e37eda32871445","c3df3ac9a3b84d36a9ca620a56d5fe4d","93105db653db4215b442e964f3b14836","2c72612152274873b5e9ec12ddef696b","23aa8f3a16354343b896ee5c940bd9d2","9c4a72d9e55f4a0591dec09af75909d9","190efba9359748ab98bedd42e2843658","f1efaaa5f7184b92827feeab31ffc028","76949c0e80774de6b7affd2d55d0c66b","f624d97d659a4cf7a92bef89931f74ba","fa45cf8969e84dfa9ef38956a594b409","819c4074b47b46eda3e1e3ffc1ddec5c","6c2c979cf2084c89a1e102ceef689d3f","ffbb74da8cbd41e5b28ba1da1e0e910c","a9d573ef720f42a18874637644ea3c3a","62df1ce3b8004d00a0d645b67785ebec","b8e7bdf9b6884fd78cc7b5b463c9d591","a5fee794483e4eb18f40e4340984f5f2","74aab7ccb558407fbfdde78af78b5eb2","018ee9aa1cf648a3b9dd0bc136f26277","a587ab5355584be885d64841c02c158c","8ed17bc05fa84b99baeef1d246ea22b1","8df7c6234abc4df697e5e77d01c387f2","e3f820413c324d36a82ffb698d8ca31e","7006d6c50e784a12be23a8dd8e322122","3ed0355d2eda4104bd129dbf392df674","e5df94aa667e4784970cb49ab1fc3160","1d4b4944795e4c5aae376b7e5f2930e8","4633d68144fb47bc8d3a0c39b7e6f371","d8bcd745e82644309d6e7f3266feeba6","72ec3ed68cce4f7aa299e80e977df69c","3791aa1f74034e6684c0947fc7b20815","b4160f072c0b4631ad08da0ddfe29387","a033689549b14960b74ddf1534bb3daf"]},"executionInfo":{"status":"ok","timestamp":1589425068431,"user_tz":180,"elapsed":5826795,"user":{"displayName":"Thomás Antonio Portugal Pereira Teixeira","photoUrl":"https://lh6.googleusercontent.com/-8F88VYofNwE/AAAAAAAAAAI/AAAAAAAAAC0/1322bIdNuZA/s64/photo.jpg","userId":"18296200456625122883"}},"outputId":"997f2d2b-67f8-4ef7-9366-91205e5ae3f8"},"source":["for mode in modes:\n","  for custom_flag in custom_decoding:\n","    if custom_flag:\n","      print(\"Custom Decoding: {}\".format(mode))\n","    else:\n","      print(\"Native Decoding: {}\".format(mode))\n","    model.custom_decoding = custom_flag\n","    model.mode_decoding = mode\n","    trainer.test(model)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Custom Decoding: greedy\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"acec784780a44fff97cf4be95dd5475d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","\n","Source:In this way, the civil life of a nation matures, making it possible for all citizens to enjoy the fruits of genuine tolerance and mutual respect.\n","Target: Deste modo, a vida civil de uma nação amadurece, fazendo com que todos os cidadãos gozem dos frutos da tolerância genuína e do respeito mútuo.\n","Predicted: : Assim, a vida civil de uma naç ⁇ o madura, tornando poss\n","\n","\n","\n","--------------------------------------------------------------------------------\n","TEST RESULTS\n","{'avg_test_bleu': 14.20403907865615}\n","--------------------------------------------------------------------------------\n","\n","Native Decoding: greedy\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4bd1be7780845248e434e6ac9a376fe","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","\n","Source:In this way, the civil life of a nation matures, making it possible for all citizens to enjoy the fruits of genuine tolerance and mutual respect.\n","Target: Deste modo, a vida civil de uma nação amadurece, fazendo com que todos os cidadãos gozem dos frutos da tolerância genuína e do respeito mútuo.\n","Predicted: : Assim, a vida civil de uma naç ⁇ o madura, tornando pos\n","\n","\n","\n","--------------------------------------------------------------------------------\n","TEST RESULTS\n","{'avg_test_bleu': 13.654318474953346}\n","--------------------------------------------------------------------------------\n","\n","Custom Decoding: topk\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93105db653db4215b442e964f3b14836","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","\n","Source:In this way, the civil life of a nation matures, making it possible for all citizens to enjoy the fruits of genuine tolerance and mutual respect.\n","Target: Deste modo, a vida civil de uma nação amadurece, fazendo com que todos os cidadãos gozem dos frutos da tolerância genuína e do respeito mútuo.\n","Predicted: : Assim a vida civil de um mundo madura e tornando a todos \n","\n","\n","\n","--------------------------------------------------------------------------------\n","TEST RESULTS\n","{'avg_test_bleu': 11.080831520151133}\n","--------------------------------------------------------------------------------\n","\n","Native Decoding: topk\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa45cf8969e84dfa9ef38956a594b409","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","\n","Source:In this way, the civil life of a nation matures, making it possible for all citizens to enjoy the fruits of genuine tolerance and mutual respect.\n","Target: Deste modo, a vida civil de uma nação amadurece, fazendo com que todos os cidadãos gozem dos frutos da tolerância genuína e do respeito mútuo.\n","Predicted: : Assim se madria a vida civil de uma naç ⁇ o, tornando\n","\n","\n","\n","--------------------------------------------------------------------------------\n","TEST RESULTS\n","{'avg_test_bleu': 10.626852864767901}\n","--------------------------------------------------------------------------------\n","\n","Custom Decoding: nucleus\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74aab7ccb558407fbfdde78af78b5eb2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","\n","Source:In this way, the civil life of a nation matures, making it possible for all citizens to enjoy the fruits of genuine tolerance and mutual respect.\n","Target: Deste modo, a vida civil de uma nação amadurece, fazendo com que todos os cidadãos gozem dos frutos da tolerância genuína e do respeito mútuo.\n","Predicted: : Assim a vida civil de uma naç ⁇ o se matura, tornando poss\n","\n","\n","\n","--------------------------------------------------------------------------------\n","TEST RESULTS\n","{'avg_test_bleu': 11.762992210742995}\n","--------------------------------------------------------------------------------\n","\n","Native Decoding: nucleus\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5df94aa667e4784970cb49ab1fc3160","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","\n","Source:In this way, the civil life of a nation matures, making it possible for all citizens to enjoy the fruits of genuine tolerance and mutual respect.\n","Target: Deste modo, a vida civil de uma nação amadurece, fazendo com que todos os cidadãos gozem dos frutos da tolerância genuína e do respeito mútuo.\n","Predicted: : Tal modo, a vida civil de uma naç ⁇ o for dou por tornar també\n","\n","\n","\n","--------------------------------------------------------------------------------\n","TEST RESULTS\n","{'avg_test_bleu': 10.648199005008646}\n","--------------------------------------------------------------------------------\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"41ZKXCzsgPIC","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}